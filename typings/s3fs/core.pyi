"""
This type stub file was generated by pyright.
"""

import os
from typing import Optional, Tuple
from fsspec.spec import AbstractBufferedFile
from fsspec.asyn import AbstractAsyncStreamedFile, AsyncFileSystem
from aiohttp import ClientPayloadError

logger = ...
def setup_logging(level=...):
    ...

if "S3FS_LOGGING_LEVEL" in os.environ:
    ...
MANAGED_COPY_THRESHOLD = ...
S3_RETRYABLE_ERRORS = ...
if ClientPayloadError is not None:
    ...
_VALID_FILE_MODES = ...
_PRESERVE_KWARGS = ...
key_acls = ...
buck_acls = ...
def version_id_kw(version_id):
    """Helper to make versionId kwargs.

    Not all boto3 methods accept a None / empty versionId so dictionary expansion solves
    that problem.
    """
    ...

class S3FileSystem(AsyncFileSystem):
    """
    Access S3 as if it were a file system.

    This exposes a filesystem-like API (ls, cp, open, etc.) on top of S3
    storage.

    Provide credentials either explicitly (``key=``, ``secret=``) or depend
    on boto's credential methods. See botocore documentation for more
    information. If no credentials are available, use ``anon=True``.

    Parameters
    ----------
    anon : bool (False)
        Whether to use anonymous connection (public buckets only). If False,
        uses the key/secret given, or boto's credential resolver (client_kwargs,
        environment, variables, config files, EC2 IAM server, in that order)
    endpoint_url : string (None)
        Use this endpoint_url, if specified. Needed for connecting to non-AWS
        S3 buckets. Takes precedence over `endpoint_url` in client_kwargs.
    key : string (None)
        If not anonymous, use this access key ID, if specified. Takes precedence
        over `aws_access_key_id` in client_kwargs.
    secret : string (None)
        If not anonymous, use this secret access key, if specified. Takes
        precedence over `aws_secret_access_key` in client_kwargs.
    token : string (None)
        If not anonymous, use this security token, if specified
    use_ssl : bool (True)
        Whether to use SSL in connections to S3; may be faster without, but
        insecure. If ``use_ssl`` is also set in ``client_kwargs``,
        the value set in ``client_kwargs`` will take priority.
    s3_additional_kwargs : dict of parameters that are used when calling s3 api
        methods. Typically used for things like "ServerSideEncryption".
    client_kwargs : dict of parameters for the botocore client
    requester_pays : bool (False)
        If RequesterPays buckets are supported.
    default_block_size: int (None)
        If given, the default block size value used for ``open()``, if no
        specific value is given at all time. The built-in default is 5MB.
    default_fill_cache : Bool (True)
        Whether to use cache filling with open by default. Refer to
        ``S3File.open``.
    default_cache_type : string ("readahead")
        If given, the default cache_type value used for ``open()``. Set to "none"
        if no caching is desired. See fsspec's documentation for other available
        cache_type values. Default cache_type is "readahead".
    version_aware : bool (False)
        Whether to support bucket versioning.  If enable this will require the
        user to have the necessary IAM permissions for dealing with versioned
        objects. Note that in the event that you only need to work with the
        latest version of objects in a versioned bucket, and do not need the
        VersionId for those objects, you should set ``version_aware`` to False
        for performance reasons. When set to True, filesystem instances will
        use the S3 ListObjectVersions API call to list directory contents,
        which requires listing all historical object versions.
    cache_regions : bool (False)
        Whether to cache bucket regions or not. Whenever a new bucket is used,
        it will first find out which region it belongs and then use the client
        for that region.
    asynchronous :  bool (False)
        Whether this instance is to be used from inside coroutines.
    config_kwargs : dict of parameters passed to ``botocore.client.Config``
    kwargs : other parameters for core session.
    session : aiobotocore AioSession object to be used for all connections.
         This session will be used inplace of creating a new session inside S3FileSystem.
         For example: aiobotocore.session.AioSession(profile='test_user')

    The following parameters are passed on to fsspec:

    skip_instance_cache: to control reuse of instances
    use_listings_cache, listings_expiry_time, max_paths: to control reuse of directory listings

    Examples
    --------
    >>> s3 = S3FileSystem(anon=False)  # doctest: +SKIP
    >>> s3.ls('my-bucket/')  # doctest: +SKIP
    ['my-file.txt']

    >>> with s3.open('my-bucket/my-file.txt', mode='rb') as f:  # doctest: +SKIP
    ...     print(f.read())  # doctest: +SKIP
    b'Hello, world!'
    """
    root_marker = ...
    connect_timeout = ...
    retries = ...
    read_timeout = ...
    default_block_size = ...
    protocol = ...
    _extra_tokenize_attributes = ...
    def __init__(self, anon=..., endpoint_url=..., key=..., secret=..., token=..., use_ssl=..., client_kwargs=..., requester_pays=..., default_block_size=..., default_fill_cache=..., default_cache_type=..., version_aware=..., config_kwargs=..., s3_additional_kwargs=..., session=..., username=..., password=..., cache_regions=..., asynchronous=..., loop=..., **kwargs) -> None:
        ...
    
    @property
    def s3(self):
        ...
    
    async def get_s3(self, bucket=...):
        ...
    
    call_s3 = ...
    def split_path(self, path) -> Tuple[str, str, Optional[str]]:
        """
        Normalise S3 path string into bucket and key.

        Parameters
        ----------
        path : string
            Input path, like `s3://mybucket/path/to/file`

        Examples
        --------
        >>> split_path("s3://mybucket/path/to/file")
        ['mybucket', 'path/to/file', None]

        >>> split_path("s3://mybucket/path/to/versioned_file?versionId=some_version_id")
        ['mybucket', 'path/to/versioned_file', 'some_version_id']
        """
        ...
    
    async def set_session(self, refresh=..., kwargs=...):
        """Establish S3 connection object.
        Returns
        -------
        Session to be closed later with await .close()
        """
        ...
    
    _connect = ...
    connect = ...
    @staticmethod
    def close_session(loop, s3):
        ...
    
    get_delegated_s3pars = ...
    find = ...
    mkdir = ...
    makedirs = ...
    rmdir = ...
    exists = ...
    touch = ...
    checksum = ...
    isdir = ...
    object_version_info = ...
    _metadata_cache = ...
    metadata = ...
    def get_tags(self, path):
        """Retrieve tag key/values for the given path

        Returns
        -------
        {str: str}
        """
        ...
    
    def put_tags(self, path, tags, mode=...):
        """Set tags for given existing key

        Tags are a str:str mapping that can be attached to any key, see
        https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/allocation-tag-restrictions.html

        This is similar to, but distinct from, key metadata, which is usually
        set at key creation time.

        Parameters
        ----------
        path: str
            Existing key to attach tags to
        tags: dict str, str
            Tags to apply.
        mode:
            One of 'o' or 'm'
            'o': Will over-write any existing tags.
            'm': Will merge in new tags with existing tags.  Incurs two remote
            calls.
        """
        ...
    
    getxattr = ...
    setxattr = ...
    chmod = ...
    url = ...
    merge = ...
    list_multipart_uploads = ...
    clear_multipart_uploads = ...
    is_bucket_versioned = ...
    make_bucket_versioned = ...
    def invalidate_cache(self, path=...):
        ...
    
    def modified(self, path, version_id=..., refresh=...):
        """Return the last modified timestamp of file at `path` as a datetime"""
        ...
    
    def sign(self, path, expiration=..., **kwargs):
        ...
    
    invalidate_region_cache = ...
    async def open_async(self, path, mode=..., **kwargs):
        ...
    


class S3File(AbstractBufferedFile):
    """
    Open S3 key as a file. Data is only loaded and cached on demand.

    Parameters
    ----------
    s3 : S3FileSystem
        botocore connection
    path : string
        S3 bucket/key to access
    mode : str
        One of 'rb', 'wb', 'ab'. These have the same meaning
        as they do for the built-in `open` function.
    block_size : int
        read-ahead size for finding delimiters
    fill_cache : bool
        If seeking to new a part of the file beyond the current buffer,
        with this True, the buffer will be filled between the sections to
        best support random access. When reading only a few specific chunks
        out of a file, performance may be better if False.
    acl: str
        Canned ACL to apply
    version_id : str
        Optional version to read the file at.  If not specified this will
        default to the current version of the object.  This is only used for
        reading.
    requester_pays : bool (False)
        If RequesterPays buckets are supported.

    Examples
    --------
    >>> s3 = S3FileSystem()  # doctest: +SKIP
    >>> with s3.open('my-bucket/my-file.txt', mode='rb') as f:  # doctest: +SKIP
    ...     ...  # doctest: +SKIP

    See Also
    --------
    S3FileSystem.open: used to create ``S3File`` objects

    """
    retries = ...
    part_min = ...
    part_max = ...
    def __init__(self, s3, path, mode=..., block_size=..., acl=..., version_id=..., fill_cache=..., s3_additional_kwargs=..., autocommit=..., cache_type=..., requester_pays=..., cache_options=..., size=...) -> None:
        ...
    
    def metadata(self, refresh=..., **kwargs):
        """Return metadata of file.
        See :func:`~s3fs.S3Filesystem.metadata`.

        Metadata is cached unless `refresh=True`.
        """
        ...
    
    def getxattr(self, xattr_name, **kwargs):
        """Get an attribute from the metadata.
        See :func:`~s3fs.S3Filesystem.getxattr`.

        Examples
        --------
        >>> mys3file.getxattr('attribute_1')  # doctest: +SKIP
        'value_1'
        """
        ...
    
    def setxattr(self, copy_kwargs=..., **kwargs):
        """Set metadata.
        See :func:`~s3fs.S3Filesystem.setxattr`.

        Examples
        --------
        >>> mys3file.setxattr(attribute_1='value1', attribute_2='value2')  # doctest: +SKIP
        """
        ...
    
    def url(self, **kwargs):
        """HTTP URL to read this file (if it already exists)"""
        ...
    
    def commit(self):
        ...
    
    def discard(self):
        ...
    


class S3AsyncStreamedFile(AbstractAsyncStreamedFile):
    def __init__(self, fs, path, mode) -> None:
        ...
    
    async def read(self, length=...):
        ...
    



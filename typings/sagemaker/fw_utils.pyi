"""
This type stub file was generated by pyright.
"""

from typing import Dict, List, Optional, Union
from sagemaker.instance_group import InstanceGroup
from sagemaker.session_settings import SessionSettings
from sagemaker.workflow.entities import PipelineVariable

"""
This type stub file was generated by pyright.
"""
logger = ...
_TAR_SOURCE_FILENAME = ...
UploadedCode = ...
PYTHON_2_DEPRECATION_WARNING = ...
PARAMETER_SERVER_MULTI_GPU_WARNING = ...
DEBUGGER_UNSUPPORTED_REGIONS = ...
PROFILER_UNSUPPORTED_REGIONS = ...
SINGLE_GPU_INSTANCE_TYPES = ...
SM_DATAPARALLEL_SUPPORTED_INSTANCE_TYPES = ...
SM_DATAPARALLEL_SUPPORTED_FRAMEWORK_VERSIONS = ...
PYTORCHDDP_SUPPORTED_FRAMEWORK_VERSIONS = ...
TORCH_DISTRIBUTED_GPU_SUPPORTED_FRAMEWORK_VERSIONS = ...
TRAINIUM_SUPPORTED_DISTRIBUTION_STRATEGIES = ...
TRAINIUM_SUPPORTED_TORCH_DISTRIBUTED_FRAMEWORK_VERSIONS = ...
SMDISTRIBUTED_SUPPORTED_STRATEGIES = ...
GRAVITON_ALLOWED_TARGET_INSTANCE_FAMILY = ...
GRAVITON_ALLOWED_FRAMEWORKS = ...
def validate_source_dir(script, directory):
    """Validate that the source directory exists and it contains the user script.

    Args:
        script (str): Script filename.
        directory (str): Directory containing the source file.
    Raises:
        ValueError: If ``directory`` does not exist, is not a directory, or does
            not contain ``script``.
    """
    ...

def validate_source_code_input_against_pipeline_variables(entry_point: Optional[Union[str, PipelineVariable]] = ..., source_dir: Optional[Union[str, PipelineVariable]] = ..., git_config: Optional[Dict[str, str]] = ..., enable_network_isolation: Union[bool, PipelineVariable] = ...):
    """Validate source code input against pipeline variables

    Args:
        entry_point (str or PipelineVariable): The path to the local Python source file that
            should be executed as the entry point to training (default: None).
        source_dir (str or PipelineVariable): The Path to a directory with any other
            training source code dependencies aside from the entry point file (default: None).
        git_config (Dict[str, str]): Git configurations used for cloning files (default: None).
        enable_network_isolation (bool or PipelineVariable): Specifies whether container will run
            in network isolation mode (default: False).
    """
    ...

def parse_mp_parameters(params):
    """Parse the model parallelism parameters provided by the user.

    Args:
        params: a string representing path to an existing config, or
                a config dict.

    Returns:
        parsed: a dict of parsed config.

    Raises:
        ValueError: if params is not a string or a dict, or
                    the config file cannot be parsed as json.
    """
    ...

def get_mp_parameters(distribution):
    """Get the model parallelism parameters provided by the user.

    Args:
        distribution: distribution dictionary defined by the user.

    Returns:
        params: dictionary containing model parallelism parameters
        used for training.
    """
    ...

def validate_mp_config(config):
    """Validate the configuration dictionary for model parallelism.

    Args:
       config (dict): Dictionary holding configuration keys and values.

    Raises:
        ValueError: If any of the keys have incorrect values.
    """
    ...

def tar_and_upload_dir(session, bucket, s3_key_prefix, script, directory=..., dependencies=..., kms_key=..., s3_resource=..., settings: Optional[SessionSettings] = ...) -> UploadedCode:
    """Package source files and upload a compress tar file to S3.

    The S3 location will be ``s3://<bucket>/s3_key_prefix/sourcedir.tar.gz``.
    If directory is an S3 URI, an UploadedCode object will be returned, but
    nothing will be uploaded to S3 (this allow reuse of code already in S3).
    If directory is None, the script will be added to the archive at
    ``./<basename of script>``. If directory is not None, the (recursive) contents
    of the directory will be added to the archive. directory is treated as the base
    path of the archive, and the script name is assumed to be a filename or relative path
    inside the directory.

    Args:
        session (boto3.Session): Boto session used to access S3.
        bucket (str): S3 bucket to which the compressed file is uploaded.
        s3_key_prefix (str): Prefix for the S3 key.
        script (str): Script filename or path.
        directory (str): Optional. Directory containing the source file. If it
            starts with "s3://", no action is taken.
        dependencies (List[str]): Optional. A list of paths to directories
            (absolute or relative) containing additional libraries that will be
            copied into /opt/ml/lib
        kms_key (str): Optional. KMS key ID used to upload objects to the bucket
            (default: None).
        s3_resource (boto3.resource("s3")): Optional. Pre-instantiated Boto3 Resource
            for S3 connections, can be used to customize the configuration,
            e.g. set the endpoint URL (default: None).
        settings (sagemaker.session_settings.SessionSettings): Optional. The settings
            of the SageMaker ``Session``, can be used to override the default encryption
            behavior (default: None).
    Returns:
        sagemaker.fw_utils.UploadedCode: An object with the S3 bucket and key (S3 prefix) and
            script name.
    """
    ...

def framework_name_from_image(image_uri):
    """Extract the framework and Python version from the image name.

    Args:
        image_uri (str): Image URI, which should be one of the following forms:
            legacy:
            '<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-<fw>-<py_ver>-<device>:<container_version>'
            legacy:
            '<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-<fw>-<py_ver>-<device>:<fw_version>-<device>-<py_ver>'
            current:
            '<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-<fw>:<fw_version>-<device>-<py_ver>'
            current:
            '<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-rl-<fw>:<rl_toolkit><rl_version>-<device>-<py_ver>'
            current:
            '<account>.dkr.ecr.<region>.amazonaws.com/<fw>-<image_scope>:<fw_version>-<device>-<py_ver>'
            current:
            '<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-xgboost:<fw_version>-<container_version>'

    Returns:
        tuple: A tuple containing:

            - str: The framework name
            - str: The Python version
            - str: The image tag
            - str: If the TensorFlow image is script mode
    """
    ...

def framework_version_from_tag(image_tag):
    """Extract the framework version from the image tag.

    Args:
        image_tag (str): Image tag, which should take the form
            '<framework_version>-<device>-<py_version>'
            '<xgboost_version>-<container_version>'

    Returns:
        str: The framework version.
    """
    ...

def model_code_key_prefix(code_location_key_prefix, model_name, image):
    """Returns the s3 key prefix for uploading code during model deployment.

    The location returned is a potential concatenation of 2 parts
        1. code_location_key_prefix if it exists
        2. model_name or a name derived from the image

    Args:
        code_location_key_prefix (str): the s3 key prefix from code_location
        model_name (str): the name of the model
        image (str): the image from which a default name can be extracted

    Returns:
        str: the key prefix to be used in uploading code
    """
    ...

def warn_if_parameter_server_with_multi_gpu(training_instance_type, distribution):
    """Warn the user about training when it doesn't leverage all the GPU cores.

    Warn the user that training will not fully leverage all the GPU
    cores if parameter server is enabled and a multi-GPU instance is selected.
    Distributed training with the default parameter server setup doesn't
    support multi-GPU instances.

    Args:
        training_instance_type (str): A string representing the type of training instance selected.
        distribution (dict): A dictionary with information to enable distributed training.
            (Defaults to None if distributed training is not enabled.) For example:

            .. code:: python

                {
                    "parameter_server": {
                        "enabled": True
                    }
                }


    """
    ...

def profiler_config_deprecation_warning(profiler_config, image_uri, framework_name, framework_version):
    """Put out a deprecation message for if framework profiling is specified TF >= 2.12 and PT >= 2.0"""
    ...

def validate_smdistributed(instance_type, framework_name, framework_version, py_version, distribution, image_uri=...):
    """Check if smdistributed strategy is correctly invoked by the user.

    Currently, two strategies are supported: `dataparallel` or `modelparallel`.
    Validate if the user requested strategy is supported.

    Currently, only one strategy can be specified at a time. Validate if the user has requested
    more than one strategy simultaneously.

    Validate if the smdistributed dict arg is syntactically correct.

    Additionally, perform strategy-specific validations.

    Args:
        instance_type (str): A string representing the type of training instance selected.
        framework_name (str): A string representing the name of framework selected.
        framework_version (str): A string representing the framework version selected.
        py_version (str): A string representing the python version selected.
        distribution (dict): A dictionary with information to enable distributed training.
            (Defaults to None if distributed training is not enabled.) For example:

            .. code:: python

                {
                    "smdistributed": {
                        "dataparallel": {
                            "enabled": True
                        }
                    }
                }
        image_uri (str): A string representing a Docker image URI.

    Raises:
        ValueError: if distribution dictionary isn't correctly formatted or
            multiple strategies are requested simultaneously or
            an unsupported strategy is requested or
            strategy-specific inputs are incorrect/unsupported
    """
    ...

def validate_distribution(distribution: Dict, instance_groups: List[InstanceGroup], framework_name: str, framework_version: str, py_version: str, image_uri: str, kwargs: Dict) -> Dict:
    """Check if distribution strategy is correctly invoked by the user.

    Currently, check for `dataparallel`, `modelparallel` and heterogeneous cluster set up.
    Validate if the user requested strategy is supported.

    Args:
        distribution (dict): A dictionary with information to enable distributed training.
            (Defaults to None if distributed training is not enabled.) For example:

            .. code:: python

                {
                    "smdistributed": {
                        "dataparallel": {
                            "enabled": True
                        }
                    }
                }
        instance_groups ([InstanceGroup]): A list contains instance groups used for training.
        framework_name (str): A string representing the name of framework selected.
        framework_version (str): A string representing the framework version selected.
        py_version (str): A string representing the python version selected.
        image_uri (str): A string representing a Docker image URI.
        kwargs(dict): Additional kwargs passed to this function

    Returns:
        distribution(dict): updated dictionary with validated information
            to enable distributed training.

    Raises:
        ValueError: if distribution dictionary isn't correctly formatted or
            multiple strategies are requested simultaneously or
            an unsupported strategy is requested or
            strategy-specific inputs are incorrect/unsupported or
            heterogeneous cluster set up is incorrect
    """
    ...

def validate_distribution_for_instance_type(instance_type, distribution):
    """Check if the provided distribution strategy is supported for the instance_type

    Args:
        instance_type (str): A string representing the type of training instance selected.
        distribution (dict): A dictionary with information to enable distributed training.
    """
    ...

def validate_pytorch_distribution(distribution, framework_name, framework_version, py_version, image_uri):
    """Check if pytorch distribution strategy is correctly invoked by the user.

    Args:
        distribution (dict): A dictionary with information to enable distributed training.
            (Defaults to None if distributed training is not enabled.) For example:

            .. code:: python

                {
                    "pytorchddp": {
                        "enabled": True
                    }
                }
        framework_name (str): A string representing the name of framework selected.
        framework_version (str): A string representing the framework version selected.
        py_version (str): A string representing the python version selected.
        image_uri (str): A string representing a Docker image URI.

    Raises:
        ValueError: if
            `py_version` is not python3 or
            `framework_version` is not in PYTORCHDDP_SUPPORTED_FRAMEWORK_VERSIONS
    """
    ...

def validate_torch_distributed_distribution(instance_type, distribution, framework_version, py_version, image_uri, entry_point):
    """Check if torch_distributed distribution strategy is correctly invoked by the user.

    Args:
        instance_type (str): A string representing the type of training instance selected.
        distribution (dict): A dictionary with information to enable distributed training.
            (Defaults to None if distributed training is not enabled.) For example:

            .. code:: python

                {
                    "torch_distributed": {
                        "enabled": True
                    }
                }
        framework_version (str): A string representing the framework version selected.
        py_version (str): A string representing the python version selected.
        image_uri (str): A string representing a Docker image URI.
        entry_point (str or PipelineVariable): The absolute or relative path to the local Python
            source file that should be executed as the entry point to
            training.

    Raises:
        ValueError: if
            `py_version` is not python3 or
            `framework_version` is not compatible with instance types
    """
    ...

def python_deprecation_warning(framework, latest_supported_version):
    """Placeholder docstring"""
    ...

def validate_version_or_image_args(framework_version, py_version, image_uri):
    """Checks if version or image arguments are specified.

    Validates framework and model arguments to enforce version or image specification.

    Args:
        framework_version (str): The version of the framework.
        py_version (str): The version of Python.
        image_uri (str): The URI of the image.

    Raises:
        ValueError: if `image_uri` is None and either `framework_version` or `py_version` is
            None.
    """
    ...

def create_image_uri(region, framework, instance_type, framework_version, py_version=..., account=..., accelerator_type=..., optimized_families=...):
    """Deprecated method. Please use sagemaker.image_uris.retrieve().

    Args:
        region (str): AWS region where the image is uploaded.
        framework (str): framework used by the image.
        instance_type (str): SageMaker instance type. Used to determine device
            type (cpu/gpu/family-specific optimized).
        framework_version (str): The version of the framework.
        py_version (str): Optional. Python version. If specified, should be one
            of 'py2' or 'py3'. If not specified, image uri will not include a
            python component.
        account (str): AWS account that contains the image. (default:
            '520713654638')
        accelerator_type (str): SageMaker Elastic Inference accelerator type.
        optimized_families (str): Deprecated. A no-op argument.

    Returns:
        the image uri
    """
    ...

